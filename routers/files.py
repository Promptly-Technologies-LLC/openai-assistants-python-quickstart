import os
import logging
from typing import List, Dict
from dotenv import load_dotenv
from fastapi import APIRouter, Request, UploadFile, File, HTTPException, Depends, Form, Path
from fastapi.responses import StreamingResponse
from openai import AsyncOpenAI
from openai.types.file_purpose import FilePurpose
from utils.files import get_or_create_vector_store
from utils.streaming import stream_file_content

logger = logging.getLogger("uvicorn.error")

# Get assistant ID from environment variables
load_dotenv(override=True)
assistant_id_env = os.getenv("ASSISTANT_ID")
if not assistant_id_env:
    raise ValueError("ASSISTANT_ID environment variable not set")
assistant_id: str = assistant_id_env

router = APIRouter(
    prefix="/assistants/{assistant_id}/files",
    tags=["assistants_files"]
)


#TODO: Correctly return HTML, not JSON, from the routes below

@router.get("/")
async def list_files(client: AsyncOpenAI = Depends(lambda: AsyncOpenAI())) -> List[Dict[str, str]]:
    # List files in the vector store
    vector_store_id = await get_or_create_vector_store(assistant_id, client)
    file_list = await client.vector_stores.files.list(vector_store_id)
    files_array: List[Dict[str, str]] = []
    
    if file_list.data:
        for file in file_list.data:
            file_details = await client.files.retrieve(file.id)
            vector_file_details = await client.vector_stores.files.retrieve(
                vector_store_id=vector_store_id,
                file_id=file.id
            )
            files_array.append({
                "file_id": file.id,
                "filename": file_details.filename or "unknown_filename",
                "status": vector_file_details.status or "unknown_status",
            })
    return files_array


# Take a purpose parameter, defaulting to "assistants"
@router.post("/")
async def upload_file(file: UploadFile = File(...), purpose: FilePurpose = Form(default="assistants")) -> Dict[str, str]:
    try:
        client = AsyncOpenAI()
        vector_store_id = await get_or_create_vector_store(assistant_id)
        openai_file = await client.files.create(
            file=file.file,
            purpose=purpose
        )
        await client.vector_stores.files.create(
            vector_store_id=vector_store_id,
            file_id=openai_file.id
        )
        return {"message": "File uploaded successfully"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/delete")
async def delete_file(
    request: Request, 
    fileId: str = Form(...), 
    client: AsyncOpenAI = Depends(lambda: AsyncOpenAI())
) -> Dict[str, str]:
    vector_store_id = await get_or_create_vector_store(assistant_id, client)
    await client.vector_stores.files.delete(vector_store_id=vector_store_id, file_id=fileId)
    return {"message": "File deleted successfully"}


# --- Streaming file content ---




@router.get("/{file_id}")
async def download_assistant_file(
    file_id: str = Path(..., description="The ID of the file to retrieve"),
    client: AsyncOpenAI = Depends(lambda: AsyncOpenAI())
) -> StreamingResponse:
    try:
        file = await client.files.retrieve(file_id)
        file_content = await client.files.content(file_id)
        
        if not hasattr(file_content, 'content'):
            raise HTTPException(status_code=500, detail="File content not available")
            
        return StreamingResponse(
            stream_file_content(file_content.content),
            headers={"Content-Disposition": f'attachment; filename=\"{file.filename or "download"}\"'}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{file_id}/content")
async def get_assistant_image_content(
    file_id: str,
    client: AsyncOpenAI = Depends(lambda: AsyncOpenAI())
) -> StreamingResponse:
    """
    Streams file content from OpenAI API.
    This route is used to serve images and other files generated by the code interpreter.
    """
    try:
        # Get the file content from OpenAI
        file_content = await client.files.content(file_id)
        file_bytes = file_content.read()  # Remove await since read() returns bytes directly

        # Return the file content as a streaming response
        # Note: In a production environment, you might want to add caching
        return StreamingResponse(
            content=iter([file_bytes]),
            media_type="image/png"  # You might want to make this dynamic based on file type
        )
    except Exception as e:
        logger.error(f"Error getting file content: {e}")
        raise HTTPException(status_code=500, detail=str(e))
